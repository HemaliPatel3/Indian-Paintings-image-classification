{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974755cf",
   "metadata": {},
   "source": [
    "# INDIAN PAINTINGS IMAGE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16026dc",
   "metadata": {},
   "source": [
    "## import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc69bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436f2ed",
   "metadata": {},
   "source": [
    "## Set Up Database Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'paintings'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d736f",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224  # MobileNet input size\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd62364",
   "metadata": {},
   "source": [
    "## Build the Transfer Learning Model with MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))  # 8 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfb5e2",
   "metadata": {},
   "source": [
    "## Freeze the base model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ec962",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6640441",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the Model\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs= 25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    #callbacks=[reduce_lr, early_stop]\n",
    ")\n",
    "# Step 6: Evaluate the Model\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5e5e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Intel\\openvino_env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('MobileNet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef2e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 893ms/step\n",
      "Image: gond painting_1.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: gond painting_10.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Image: gond painting_2.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: gond painting_3.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: gond painting_4.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Image: gond painting_5.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Image: gond painting_6.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: gond painting_7.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Image: gond painting_8.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: gond painting_9.jpg, Predicted Class: gond\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: kalighat painting6.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: kalighat painting_1.jpg, Predicted Class: kalighat\n",
      "Error loading image: C:\\Users\\Hemali Patel\\Desktop\\code unnati internship\\test imgae\\kalighat painting_10.htm, cannot identify image file <_io.BytesIO object at 0x000001FD90B65760>\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Image: kalighat painting_2.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Image: kalighat painting_3.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: kalighat painting_4.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Image: kalighat painting_5.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Image: kalighat painting_7.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: kalighat painting_8.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: kalighat painting_9.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Image: kangra painting_1.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Image: kangra painting_2.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Image: kangra painting_3.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: kangra painting_4.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Image: kangra painting_5.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Image: kangra painting_6.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: kangra painting_7.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: kangra painting_8.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Image: kangra painting_9.jpg, Predicted Class: kangra\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Image: kerala mural_1.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Image: kerala mural_10.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: kerala mural_2.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Image: kerala mural_3.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Image: kerala mural_4.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: kerala mural_5.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Image: kerala mural_6.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Image: kerala mural_7.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: kerala mural_8.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Image: kerala mural_9.jpg, Predicted Class: kerala_mural\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: madhubani painting_1.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Image: madhubani painting_10.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: madhubani painting_2.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: madhubani painting_3.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: madhubani painting_4.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: madhubani painting_5.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Image: madhubani painting_6.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: madhubani painting_7.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Image: madhubani painting_8.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: madhubani painting_9.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Image: mandana art drawing_1.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: mandana art drawing_10.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: mandana art drawing_2.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: mandana art drawing_3.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Image: mandana art drawing_4.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: mandana art drawing_5.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Image: mandana art drawing_6.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Image: mandana art drawing_7.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Image: mandana art drawing_8.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Image: mandana art drawing_9.jpg, Predicted Class: mandana\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Image: pichwai painting_1.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: pichwai painting_10.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: pichwai painting_2.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: pichwai painting_3.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Image: pichwai painting_4.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: pichwai painting_5.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Image: pichwai painting_6.jpg, Predicted Class: kalighat\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: pichwai painting_7.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Image: pichwai painting_8.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: pichwai painting_9.jpg, Predicted Class: pichwai\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: warli painting_1.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: warli painting_10.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Image: warli painting_2.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: warli painting_3.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Image: warli painting_4.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: warli painting_5.jpg, Predicted Class: warli\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: warli painting_6.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Image: warli painting_7.jpg, Predicted Class: warli\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Image: warli painting_8.jpg, Predicted Class: madhubani\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Image: warli painting_9.jpg, Predicted Class: warli\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load the Trained Model\n",
    "model = load_model('MobileNet_model.h5')  # Replace with the path to your saved model\n",
    "\n",
    "# Step 2: Load the Test Data\n",
    "test_data_dir = 'C:\\\\Users\\\\Hemali Patel\\\\Desktop\\\\code unnati internship\\\\test imgae'  # Replace with the path to your test data folder\n",
    "img_width, img_height = 224, 224  # Same as the input size for ResNet50V2\n",
    "batch_size = 32\n",
    "\n",
    "# Step 3: Get the Class Labels\n",
    "class_labels = ['gond', 'kalighat', 'kangra', 'kerala_mural', 'madhubani', 'mandana', 'pichwai', 'warli']\n",
    "\n",
    "# Step 4: Make Predictions on Test Data\n",
    "def predict_image(image_path):\n",
    "    try:\n",
    "        img = image.load_img(image_path, target_size=(img_width, img_height))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match batch size\n",
    "        img_array /= 255.0  # Rescale pixel values to 0-1\n",
    "\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_class = class_labels[np.argmax(prediction)]\n",
    "\n",
    "        return predicted_class\n",
    "    except UnidentifiedImageError as e:\n",
    "        print(f\"Error loading image: {image_path}, {e}\")\n",
    "        return None\n",
    "\n",
    "test_images = os.listdir(test_data_dir)\n",
    "for image_file in test_images:\n",
    "    image_path = os.path.join(test_data_dir, image_file)\n",
    "    if os.path.isfile(image_path):\n",
    "        try:\n",
    "            predicted_class = predict_image(image_path)\n",
    "            if predicted_class is not None:\n",
    "                print(f\"Image: {image_file}, Predicted Class: {predicted_class}\")\n",
    "        except UnidentifiedImageError as e:\n",
    "            print(f\"Error processing image: {image_file}, {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf4a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 781ms/step\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "1/1 [==============================] - 1s 849ms/step\n",
      "1/1 [==============================] - 1s 782ms/step\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "Accuracy on validation data: 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 7: Calculate Accuracy\n",
    "def calculate_accuracy(model, validation_generator):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Predict classes for validation data\n",
    "    for i in range(len(validation_generator)):\n",
    "        x_val, y_val = validation_generator[i]\n",
    "        y_true.extend(np.argmax(y_val, axis=1))  # Actual labels\n",
    "        y_pred.extend(np.argmax(model.predict(x_val), axis=1))  # Predicted labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Call the function to get accuracy\n",
    "accuracy = calculate_accuracy(model, validation_generator)\n",
    "print(\"Accuracy on validation data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eaf72db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 786ms/step\n",
      "1/1 [==============================] - 1s 788ms/step\n",
      "1/1 [==============================] - 1s 846ms/step\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "Accuracy on validation data: 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 7: Calculate Accuracy\n",
    "def calculate_accuracy(model, validation_generator):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Predict classes for validation data\n",
    "    for i in range(len(validation_generator)):\n",
    "        x_val, y_val = validation_generator[i]\n",
    "        y_true.extend(np.argmax(y_val, axis=1))  # Actual labels\n",
    "        y_pred.extend(np.argmax(model.predict(x_val), axis=1))  # Predicted labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Call the function to get accuracy\n",
    "accuracy = calculate_accuracy(model, validation_generator)\n",
    "print(\"Accuracy on validation data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37862b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 791ms/step\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "1/1 [==============================] - 1s 802ms/step\n",
      "1/1 [==============================] - 1s 757ms/step\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "Accuracy on validation data: 0.8367346938775511\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 7: Calculate Accuracy\n",
    "def calculate_accuracy(model, validation_generator):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Predict classes for validation data\n",
    "    for i in range(len(validation_generator)):\n",
    "        x_val, y_val = validation_generator[i]\n",
    "        y_true.extend(np.argmax(y_val, axis=1))  # Actual labels\n",
    "        y_pred.extend(np.argmax(model.predict(x_val), axis=1))  # Predicted labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Call the function to get accuracy\n",
    "accuracy = calculate_accuracy(model, validation_generator)\n",
    "print(\"Accuracy on validation data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b471eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 848ms/step\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "1/1 [==============================] - 1s 771ms/step\n",
      "1/1 [==============================] - 1s 787ms/step\n",
      "1/1 [==============================] - 1s 511ms/step\n",
      "Accuracy on validation data: 0.7891156462585034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 7: Calculate Accuracy\n",
    "def calculate_accuracy(model, validation_generator):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Predict classes for validation data\n",
    "    for i in range(len(validation_generator)):\n",
    "        x_val, y_val = validation_generator[i]\n",
    "        y_true.extend(np.argmax(y_val, axis=1))  # Actual labels\n",
    "        y_pred.extend(np.argmax(model.predict(x_val), axis=1))  # Predicted labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Call the function to get accuracy\n",
    "accuracy = calculate_accuracy(model, validation_generator)\n",
    "print(\"Accuracy on validation data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bbdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
